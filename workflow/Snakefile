from os.path import join
import pandas as pd
from collections import defaultdict
import yaml

#config dir
source_dir = config['source_dir']
out_dir = config['output_dir'].rstrip('/') + '/'
fastq_dir = config['fastq_dir'].rstrip('/') + '/'
talon_conda = config['talon_conda']
sample_manifest=config['sample_manifest']

#config user params
annotation_id=config['annotation_id']
build_id=config['build_id']
maxFracA=config['maxFracA']
minCount=config['minCount']
minDatasets=config['minDatasets']
platform_id=config['platform_id']
primer_len=config['primer_length']
perc_sim = config['percent_similarity']
num_match = config['number_of_matches']

#ref information
anno_gtf=config['annotation_gtf']
anno_fa=config['annotation_fa']
anno_gff=config['annotation_gff']

#barcode list
df_sample = pd.read_csv(sample_manifest,sep="\t")
bc_list = df_sample['filename']

#talon config
def talon_config(wildcards):
    
    #create array for config
    config_data = []

    #for each of the barcodes, generate config info
    #example: SIRV_Rep1,SIRV,PacBio-Sequel2,/data/sevillas2/RBL3/tutorial/labeled/SIRV_rep1_labeled.sam
    for bc in bc_list:
        df_sub = df_sample[df_sample["filename"] == bc]
        
        output_filename = join(out_dir,'04_sam_labeled',bc + '_labeled.sam')
        config_data.append(df_sub.iloc[0]['sampleid'] + "," + build_id + "," + platform_id + "," + output_filename)
    
    #create config
    talon_config = join(out_dir,'03_talon', 'talon_config.csv')
    with open(talon_config, "w") as txt_file:
        for line in config_data:
            txt_file.write(line + "\n")

localrules: talon_config

rule all:
    input:
        #input fastq files
        expand(join(fastq_dir,'{bc}.fastq'),bc=bc_list),
        expand(join(out_dir,'01_fastq','{bc}.R1.fastq.gz'),bc=bc_list),

        #sam files
        expand(join(out_dir,'02_sam','{bc}_sorted.sam'),bc=bc_list),

        #bam files
        expand(join(out_dir,'03_bam','{bc}.bam'),bc=bc_list),

        #qc
        expand(join(out_dir, '00_qc','fastqc','{bc}.R1_fastqc.html'),bc=bc_list),
        expand(join(out_dir, '00_qc','samtools','{bc}_samstats.txt'),bc=bc_list),
        join(out_dir,'00_qc','multiqc_report.html'),
        join(out_dir,'00_qc','qc_report.html'),

        #talon
        join(out_dir,'03_talon', 'talon_config.csv'),
        join(out_dir,'03_talon', build_id + '.db'),
        expand(join(out_dir,'04_sam_labeled','{bc}_labeled.sam'),bc=bc_list),
        join(out_dir,'05_annotation', build_id + '_talon_read_annot.tsv'),
        join(out_dir,'06_read_counts', build_id + '_talon_summary.tsv'),
        join(out_dir,'06_read_counts', build_id + '_talon_abundance.tsv'),
        join(out_dir,'06_read_counts', build_id + '_whitelist.txt'),
        join(out_dir,'06_read_counts', build_id + '_talon_abundance_filtered.tsv'),
        join(out_dir,'07_gtf', build_id + '_talon.gtf'),

        #squanti
        #join(out_dir,'tbd'),

        #qc
        join(out_dir,'08_transcript_plots','abundance_plots.html')

        #collapsed files
        #expand(join(out_dir,'collapsed','{bc}.collapsed.gff'),bc=bc_list),
        #expand(join(out_dir,'collapsed','{bc}.collapsed.rep.fq'),bc=bc_list),
        #expand(join(out_dir,'collapsed','{bc}.collapsed.group.txt'),bc=bc_list),
        #expand(join(out_dir,'collapsed','{bc}.ignored_ids.txt'),bc=bc_list),

rule handle_fastq:
    '''
    move and zip fastq files 
    '''
    input:
        f1 = join(fastq_dir,'{bc}.fastq')
    params:
        rname = "01_fq",
        base = join(out_dir,'01_fastq','{bc}.R1.fastq'),
        unzip = join(out_dir,'01_fastq','{bc}.R1.fastq'),
    output:
        zip = join(out_dir,'01_fastq','{bc}.R1.fastq.gz')
    shell:
        '''
        cp {input.f1} {params.unzip}; \
        gzip {params.unzip}
        '''

rule create_sam:
    '''
    # cupcake tutorial
    #https://github.com/Magdoll/cDNA_Cupcake/wiki/Cupcake:-supporting-scripts-for-Iso-Seq-after-clustering-step

    minimap flags
    https://lh3.github.io/minimap2/minimap2.html
    '''
    input:
        f1 = join(out_dir,'01_fastq','{bc}.R1.fastq.gz')
    params:
        rname = "02_sam",
        fa = anno_fa
    envmodules:
        config['minimap2'],
        config['samtools']
    output:
        sam = join(out_dir,'02_sam','{bc}.sam'),
        sorted = join(out_dir,'02_sam','{bc}_sorted.sam')
    shell:
        '''
        minimap2 \
            -ax splice -t 30 --secondary=no --MD \
            {params.fa} {input.f1} > {output.sam};
        samtools sort {output.sam} -o {output.sorted}
        '''

rule create_bam:
    input:
        f1 = join(out_dir,'02_sam','{bc}_sorted.sam')
    params:
        rname='03_bam'
    envmodules:
        config['samtools']
    output:
        bam = join(out_dir,'03_bam','{bc}.bam'),
        sorted = join(out_dir, '03_bam','{bc}_sorted.bam')
    shell:
        """
        samtools view -bS {input.f1} -o {output.bam}; \
        samtools sort {output.bam} -o {output.sorted}; \
        samtools index {output.sorted}; 
        """

rule qc_fastq:
    """
    Runs FastQC report on each sample 
    """
    input:
        f1 = join(out_dir,'01_fastq','{bc}.R1.fastq.gz')
    params:
        rname='03_fqc',
        base = join(out_dir, '00_qc','fastqc'),
    envmodules:
        config['fastqc']
    output:
        o1 = join(out_dir, '00_qc','fastqc','{bc}.R1_fastqc.html')
    shell:
        """
        fastqc {input.f1} -o {params.base}
        """

rule qc_samstats:
    """
    generate statistics for sam file before deduplication
    http://www.htslib.org/doc/samtools-stats.html
    > $1
    """
    input:
        f1 = join(out_dir, '03_bam','{bc}_sorted.bam')
    params:
        rname='03_samstats'
    envmodules:
        config['samtools']
    output:
        o1 = join(out_dir, '00_qc','samtools','{bc}_samstats.txt')
    shell:
        """
        samtools view -h {input.f1} | samtools stats - > {output.o1}
        """

rule qc_multiqc:
    """
    merges FastQC reports for pre/post trimmed fastq files into MultiQC report
    https://multiqc.info/docs/#running-multiqc
    """
    input:
        f1 = expand(join(out_dir, '00_qc', 'fastqc','{bc}.R1_fastqc.html'),bc=bc_list),
        f2 = expand(join(out_dir, '00_qc', 'samtools','{bc}_samstats.txt'),bc=bc_list)
    params:
        rname = '03_multiqc',
        out = join(out_dir,'00_qc'),
        qc_config = join(source_dir,'config','multiqc_config.yaml'),
        dir_fastq = expand(join(out_dir, '00_qc', 'fastqc')),
        dir_screen_species = expand(join(out_dir, '00_qc', 'screen')),
    envmodules:
        config['multiqc']
    output:
        o1 = join(out_dir,'00_qc','multiqc_report.html')
    shell:
        """
        multiqc -f -v -c {params.qc_config} \
            -d -dd 1 {params.dir_fastq} {params.dir_screen_species} \
            -o {params.out}
        """

rule qc_alignment:
    """
    uses samtools to create a bams of unaligned reads and aligned reads
    input; print qlength col to text file
    generates plots and summmary file for aligned vs unaligned statistics
    """
    input:
        f1 = join(out_dir, '03_bam','{bc}_sorted.bam')
    params:
        rname = "03_qc_align",
        R = join(source_dir,'workflow','scripts','alignment_stats.R'),
        base = join(out_dir, '00_qc', 'alignment/')
    envmodules:
        config['samtools'],
        config['R']
    output:
        bam_a = join(out_dir, '00_qc', 'alignment','{bc}_align_len.txt'),
        bam_u = join(out_dir, '00_qc', 'alignment','{bc}_unalign_len.txt'),
        png_align = join(out_dir, '00_qc', 'alignment','{bc}_aligned.png'),
        png_unalign = join(out_dir, '00_qc', 'alignment','{bc}_unaligned.png'),
        txt_align = join(out_dir, '00_qc', 'alignment','{bc}_aligned.txt'),
        txt_unalign = join(out_dir, '00_qc', 'alignment','{bc}_unaligned.txt'),
    shell:
        """
        samtools view -F 4 {input.f1} | awk '{{print length($10)}}' > {output.bam_a}; \
        samtools view -f 4 {input.f1} | awk '{{print length($10)}}' > {output.bam_u}; \
        Rscript {params.R} {wildcards.bc} {output.bam_a} {output.bam_u} {params.base}
        """

rule qc_troubleshoot:
        """
        generates a PDF of barcode plots and alignment plots for qc troubleshooting
        """
        input:
            png_align = expand(join(out_dir, '00_qc', 'alignment','{bc}_aligned.png'), bc=bc_list),
            png_unalign = expand(join(out_dir, '00_qc', 'alignment','{bc}_unaligned.png'), bc=bc_list),
            txt_align = expand(join(out_dir, '00_qc', 'alignment','{bc}_aligned.txt'), bc=bc_list),
            txt_unalign = expand(join(out_dir, '00_qc', 'alignment','{bc}_unaligned.txt'), bc=bc_list),
        params:
            rname = "03_qc_ts",
            R = join(source_dir,'workflow','scripts','qc_report_nondemux.Rmd'),
        envmodules:
            config['R']
        output:
            o1 = join(out_dir,'00_qc','qc_report.html')
        shell:
            """
            Rscript -e 'library(rmarkdown); \
            rmarkdown::render("{params.R}",
                output_file = "{output.o1}", \
                params= list(a_txt = "{input.txt_align}", \
                    u_txt = "{input.txt_unalign}"))'
            """
            
rule talon_config:
    '''
    generate talon config
    '''
    input:
        f1 = expand(join(out_dir,'01_fastq','{bc}.R1.fastq.gz'),bc=bc_list),
    params:
        rname = "talon_config",
        process = talon_config
    output:
        o1 = join(out_dir,'03_talon','talon_config.csv')

rule talon_db:
    '''
    initialize db
    '''
    input:
        anno = anno_gtf,
    params:
        rname = "03_talon_db",
        a_id = annotation_id,
        b_id = build_id,
        base = join(out_dir,'03_talon',build_id)
    output:
        o1 = join(out_dir,'03_talon',build_id + '.db')
    container: 
        talon_conda
    shell:
        '''
        talon_initialize_database \
            --f {input.anno} \
            --a {params.a_id}\
            --g {params.b_id} \
            --o {params.base}
        '''

rule talon_prime:
    '''
    Current long-read platforms that rely on poly-(A) selection are prone to internal priming artifacts. 
    These occur when the oligo-dT primer binds off-target to A-rich sequences inside an RNA transcript 
    rather than at the end. 
    
    Records the fraction of As in the n-sized window immediately following each read alignment; output SAM 
    file with the fraction recorded in the fA:f custom SAM tag
    
    tmp_dir needs to be unique to sample; otherwise run will fail as it attempts to write over
    files with each sample
    --deleteTmp
    '''
    input:
        f1 = join(out_dir,'02_sam','{bc}.sam'),
    params:
        rname = "04_label",
        anno = anno_fa,
        base_tmp = join(out_dir,'tmp' + '_' + '{bc}'),
        base_sample = join(out_dir,'04_sam_labeled','{bc}'),
        p_len = primer_len
    output:
        o1 = join(out_dir,'04_sam_labeled','{bc}_labeled.sam'),
        o2 = join(out_dir,'04_sam_labeled','{bc}_read_labels.tsv'),
    container: 
        talon_conda
    shell:
        '''
        talon_label_reads --f {input.f1} \
            --g {params.anno} \
            --t 1 \
            --ar {params.p_len} \
            --tmpDir={params.base_tmp} \
            --deleteTmp \
            --o {params.base_sample}
        '''

rule talon_annotation:
    '''
    annotate and quantify reads; modify db
    '''
    input:
        db = join(out_dir, '03_talon', build_id + '.db'),
        t_config = join(out_dir, '03_talon', 'talon_config.csv'),
        sam = expand(join(out_dir,'04_sam_labeled','{bc}_labeled.sam'),bc=bc_list)
    params:
        rname = "05_annotate",
        b_id = build_id,
        base_tmp = join(out_dir,'tmp_annotations/'),
        base_sample = join(out_dir,'05_annotation',build_id)
    output:
        o1 = join(out_dir,'05_annotation', build_id + '_talon_read_annot.tsv'),
        o2 = join(out_dir,'05_annotation', build_id + '_QC.log'),
    container: 
        talon_conda
    shell:
        '''
        talon \
            --f {input.t_config} \
            --db {input.db} \
            --build {params.b_id} \
            --threads 5 \
            --tmp_dir {params.base_tmp} \
            --o {params.base_sample}
        '''

rule talon_summary:
    '''
    summarize how many transcripts before filtering
    '''
    input:
        db = join(out_dir,'03_talon',build_id + '.db'),
        anno = join(out_dir,'05_annotation', build_id + '_talon_read_annot.tsv'),
    params:
        rname = "06.1_summary",
        base = join(out_dir,'06_read_counts', build_id)
    output:
        o1 = join(out_dir,'06_read_counts', build_id + '_talon_summary.tsv')
    container: 
        talon_conda
    shell:
        '''
        talon_summarize --db {input.db} --v --o {params.base}
        '''

rule talon_counts:
    '''
    abundance matrix (for comp gene expression) without filtering
    '''
    input:
        db = join(out_dir,'03_talon',build_id + '.db'),
        anno = join(out_dir,'05_annotation', build_id + '_talon_read_annot.tsv'),
    params:
        rname = "06.2_abundance",
        a_id = annotation_id,
        b_id = build_id,
        base = join(out_dir,'06_read_counts', build_id)
    output:
        o1 = join(out_dir,'06_read_counts', build_id + '_talon_abundance.tsv')
    container: 
        talon_conda
    shell:
        '''
        talon_abundance --db {input.db} -a {params.a_id} --build {params.b_id} --o {params.base}
        '''

rule talon_whitelist:
    '''
    repeat with TALON filters
    '''
    input:
        db = join(out_dir,'03_talon',build_id + '.db'),
        anno = join(out_dir,'05_annotation', build_id + '_talon_read_annot.tsv'),
    params:
        rname = "06.3_whitelist",
        a_id = annotation_id,
        max_frac  = maxFracA,
        min_count = minCount,
        min_ds = minDatasets
    output:
        o1 = join(out_dir,'06_read_counts',build_id + '_whitelist.txt')
    container: 
        talon_conda
    shell:
        '''
        talon_filter_transcripts \
            --db {input.db} \
            -a {params.a_id} \
            --maxFracA {params.max_frac} \
            --minCount {params.min_count} \
            --minDatasets {params.min_ds} \
            --o {output.o1}
        '''

rule talon_abundance_filtered:
    '''
    abundance matrix (for comp gene expression) with filtering
    '''
    input:
        db = join(out_dir,'03_talon',build_id + '.db'),
        white_list = join(out_dir,'06_read_counts',build_id + '_whitelist.txt')
    params:
        rname = "06.4_abundance_filt",
        a_id = annotation_id,
        b_id = build_id,
        base = join(out_dir,'06_read_counts', build_id)
    output:
        o1 = join(out_dir,'06_read_counts', build_id + '_talon_abundance_filtered.tsv')
    container: 
        talon_conda
    shell:
        '''
        talon_abundance \
            --db {input.db} \
            -a {params.a_id} \
            --whitelist {input.white_list} \
            --build {params.b_id} \
            --o {params.base}
        '''

rule talon_gtf:
    '''
    create custom GTF of filtered transcripts
    '''
    input:
        db = join(out_dir,'03_talon',build_id + '.db'),
        w_list = join(out_dir,'06_read_counts',build_id + '_whitelist.txt')
    params:
        rname = "07_gtf",
        a_id = annotation_id,
        b_id = build_id,
        base = join(out_dir,'07_gtf', build_id)
    output:
        o1 = join(out_dir,'07_gtf', build_id + '_talon.gtf')
    container: 
        talon_conda
    shell:
        '''
        talon_create_GTF \
            --db {input.db} \
            --whitelist {input.w_list} \
            -a {params.a_id} \
            --build {params.b_id} \
            --o {params.base}
        '''

rule abundance_plots:
    input:
        unfilt = join(out_dir,'06_read_counts', build_id + '_talon_abundance.tsv'),
        filt = join(out_dir,'06_read_counts', build_id + '_talon_abundance_filtered.tsv')
    params:
        rname = "08_abundance_plots",
        R = join(source_dir,"workflow","scripts","transcript_types.Rmd"),
        base = join(out_dir,'08_transcript_plots'),
        perc_sim = perc_sim,
        num_match = num_match
    envmodules:
        config['R'],
    output:
        o1 = join(out_dir,'08_transcript_plots','abundance_plots.html')
    shell:
        '''
        Rscript -e 'library(rmarkdown); \
        rmarkdown::render("{params.R}",
            output_file = "{output.o1}", \
            params= list(f_data = "{input.filt}", \
                u_data = "{input.unfilt}", \
                output_dir = "{params.base}", \
                perc_sim = "{params.perc_sim}", \
                num_match = "{params.num_match}"))'
        '''

# rule collapse:
#     '''
#     # cupcake tutorial
#     #https://github.com/Magdoll/cDNA_Cupcake/wiki/Cupcake:-supporting-scripts-for-Iso-Seq-after-clustering-step
#     '''
#     input:
#         f1 = join(out_dir,'fastq','{bc}.R1.fastq.gz'),
#         sam = join(out_dir,'sam','{bc}_sorted.sam')
#     params:
#         rname = "create_sam",
#         bc = '{bc}',
#         script_dir = cupcake_dir,
#         py = join(source_dir,'dependencies/cDNA_Cupcake/cupcake/tofu/','collapse_isoforms_by_sam.py')
#     envmodules:
#         config['python'],
#     output:
#         o1 = join(out_dir,'collapsed','{bc}.collapsed.gff'),
#         o2 = join(out_dir,'collapsed','{bc}.collapsed.rep.fq'),
#         o3 = join(out_dir,'collapsed','{bc}.collapsed.group.txt'),
#         o4 = join(out_dir,'collapsed','{bc}.ignored_ids.txt'),
#     shell:
#         '''
#         python {params.py} \
#             --input {input.f1} \
#             --fq \
#             -s {input.sam} \
#             --dun-merge-5-shorter \
#             -o {params.bc}
#         '''

rule squanti:
    '''
    remove params: 
    --polyA_motif_list  polyA.list
    --cage_peak {params.cage} \

    for short read data only:
    --expression rsemQuantification.chr13.isoforms.results
    -c star.SJ.out.tab \
    
    sqanti3_qc.py --gtf {input.gtf} {params.anno} --fl_count {input.counts} --isoAnnotLite --gff3 {params.gff}

    '''
    input:
        gtf = join(out_dir,'07_gtf', build_id + '_talon.gtf'),
        counts = join(out_dir,'06_read_counts', build_id + '_talon_abundance_filtered.tsv')
    params:
        rname = "11_sqanti",
        anno = anno_gtf + " " + anno_fa,
        gff = anno_gff
    container: "docker://nciccbr/ccbr_sqanti_3:latest"
    output:
        o1 = join(out_dir,'tbd')
    shell:
        '''
        sqanti3_qc.py --gtf /data/sevillas2/rbl3/07_gtf/SIRV_talon.gtf /data/CCBR_Pipeliner/db/PipeDB/Indices/GTFs/hg38/gencode.v30.annotation.gtf \
            /data/CCBR_Pipeliner/db/PipeDB/Indices/hg38_30/ref.fa --fl_count /data/sevillas2/rbl3/06_read_counts/SIRV_talon_abundance_filtered.tsv \
            --isoAnnotLite --gff3 /data/CCBR/projects/rbl3/dependencies/Homo_sapiens_GRCh38_Ensembl_86.gff3
        '''

# '''
# rule :
#     input:
#         f1 = 
#     params:
#         rname = "create_sam",
#     envmodules:
#         config[''],
#     output:
#         o1 = 
#     shell:
# '''